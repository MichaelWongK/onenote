## Java内存模型

> Java内存模型规定：所有变量存在主内存，每个线程有自己的工作内存。
> 线程对变量的操作必须在工作内存进行，而不能直接对主内存进行操作。并且每个线程不能访问其他线程的工作内存。
> JAVA语言本身提供的对原子性、可见性及有序性的保证：

## synchronized、volatile区别、synchronized锁粒度、模拟死锁场景、原子性与可见性；

**synchronized**

> synchronized是Java中的关键字，是一种同步锁。有以下几种用法：

**用法**

```
1、修饰方法：在范围操作符之后，返回类型声明之前使用。每次只能有一个线程进入该方法，
		此时线程获得的是成员锁。
2、修饰代码块：每次只能有一个线程进入该代码块，
		此时线程获得的是成员锁。
3、修饰对象：如果当前线程进入，那么其他线程在该类所有对象上的任何操作都不能进行，
		此时当前线程获得的是对象锁。
4、修饰类：如果当前线程进入，那么其他线程在该类中所有操作不能进行，包括静态变量和静态方法，
		此时当前线程获得的是对象锁。
```

**synchronized补充:**

>一个同步方法调用另一个同步方法，能否得到锁？		能 synchronized实现了可重入
>
>一个同步方法调用父类的同步方法，是否可行？     可以
>
>synchronized方法遇到异常要处理，如果直接抛出异常，会释放锁

**volatile**

> volatile 关键字的作用是禁止指令的重排序，强制从公共堆栈中取得变量的值，而不是从线程私有的数据栈中取变量的值。

### **volatile与synchronized的区别如下：**

```
 1）Synchronized保证内存可见性和操作的原子性
 2）Volatile只能保证内存可见性
 3）Volatile不需要加锁，比Synchronized更轻量级，并不会阻塞线程（volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。）
 4）volatile标记的变量不会被编译器优化,而synchronized标记的变量可以被编译器优化（如编译器重排序的优化）.
 5）volatile是变量修饰符，仅能用于变量，而synchronized是一个方法或块的修饰符。
 
  volatile本质是在告诉JVM当前变量在寄存器中的值是不确定的，使用前，需要先从主存中读取，因此可以实现可见性。而对n=n+1,n++等操作时，volatile关键字将失效，不能起到像synchronized一样的线程同步（原子性）的效果。
```

**lock**

> synchronized是隐式锁，在需要同步的对象中加入此控制，而lock是显示锁，需要显示指定起始位置和终止位置。
> 使用lock时在finally中必须释放锁，不然容易造成线程死锁；而使用synchronized时，获取锁的线程会在执行完同步代码后释放锁（或者JVM会在线程执行发生异常时释放锁）。
> 使用lock时线程不会一直等待；而使用synchronized时，假设A线程获得锁后阻塞，其他线程会一直等待。
> lock可重入、可中断、可公平也可不公平；而synchronized可重入但不可中断、非公平。

## 请问什么是死锁(deadlock)?

考察点：线程死锁

**参考回答：**

> 两个线程或两个以上线程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是这些线程都陷入了无限的等待中。

> 例如，如果线程1锁住了A，然后尝试对B进行加锁，同时线程2已经锁住了B，接着尝试对A进行加锁，这时死锁就发生了。线程1永远得不到B，线程2也永远得不到A，并且它们永远也不会知道发生了这样的事情。为了得到彼此的对象（A和B），它们将永远阻塞下去。这种情况就是一个死锁。

## 请说明一下synchronized的可重入怎么实现。

考察点：锁

**参考回答：**

> 每个锁关联一个线程持有者和一个计数器。当计数器为0时表示该锁没有被任何线程持有，那么任何线程都都可能获得该锁而调用相应方法。当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。

## 请讲一下非公平锁和公平锁在reetrantlock里的实现过程是怎样的。

考察点：锁

**参考回答：**

> 如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，FIFO。对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁还需要判断当前节点是否有前驱节点，如果有，则表示有线程比当前线程更早请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁。

## 如何保证线程安全？

考察点：线程

**参考回答：**

> 通过合理的时间调度，避开共享资源的存取冲突。另外，在并行任务设计上可以通过适当的策略，保证任务与任务之间不存在共享资源，设计一个规则来保证一个客户的计算工作和数据访问只会被一个线程或一台工作机完成，而不是把一个客户的计算工作分配给多个线程去完成。

##  请你简要说明一下线程的基本状态以及状态之间的关系？

考察点：线程 

**参考回答：**

> 其中Running表示运行状态，Runnable表示就绪状态（万事俱备，只欠CPU），Blocked表示阻塞状态，阻塞状态又有多种情况，可能是因为调用wait()方法进入等待池，也可能是执行同步方法或同步代码块进入等锁池，或者是调用了sleep()方法或join()方法等待休眠或其他线程结束，或是因为发生了I/O中断。

## 请详细描述一下线程从创建到死亡的几种状态都有哪些？

考察点：JAVA线程状态

**参考回答：**

> \1. 新建( new )：新创建了一个线程对象。
> \2. 可运行( runnable )：线程对象创建后，其他线程(比如 main 线程）调用了该对象 的 start ()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获 取 cpu 的使用权 。
> \3. 运行( running )：可运行状态( runnable )的线程获得了 cpu 时间片（ timeslice ） ，执行程序代码。
> \4. 阻塞( block )：阻塞状态是指线程因为某种原因放弃了 cpu 使用权，也即让出了 cpu timeslice ，暂时停止运行。直到线程进入可运行( runnable )状态，才有 机会再次获得 cpu timeslice 转到运行( running )状态。
>
> ### **阻塞的情况分三种：**
>
> (一). 等待阻塞：运行( running )的线程执行 o . wait ()方法， JVM 会把该线程放 入等待队列( waitting queue )中。
> (二). 同步阻塞：运行( running )的线程在获取对象的同步锁时，若该同步锁 被别的线程占用，则 JVM 会把该线程放入锁池( lock pool )中。
> (三). 其他阻塞: 运行( running )的线程执行 Thread . sleep ( long ms )或 t . join ()方法，或者发出了 I / O 请求时， JVM 会把该线程置为阻塞状态。 当 sleep ()状态超时、 join ()等待线程终止或者超时、或者 I / O 处理完毕时，线程重新转入可运行( runnable )状态。
> \5. 死亡( dead )：线程 run ()、 main () 方法执行结束，或者因异常退出了 run ()方法，则该线程结束生命周期。死亡的线程不可再次复生。

## 请介绍一下线程同步和线程调度的相关方法。

考察点：线程同步

**参考回答：**

> wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；
> \- sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理InterruptedException异常；
> \- notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关；
> \- notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；
> 通过Lock接口提供了显式的锁机制（explicit lock），增强了灵活性以及对线程的协调。Lock接口中定义了加锁（lock()）和解锁（unlock()）的方法，同时还提供了newCondition()方法来产生用于线程之间通信的Condition对象；此外，Java 5还提供了信号量机制（semaphore），信号量可以用来限制对某个共享资源进行访问的线程的数量。在对资源进行访问之前，线程必须得到信号量的许可（调用Semaphore对象的acquire()方法）；在完成对资源的访问后，线程必须向信号量归还许可（调用Semaphore对象的release()方法）。

## 请简述一下线程的sleep()方法和yield()方法有什么区别？

考察点：线程

**参考回答**：

> ①sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会；
>
> ② 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态；
> ③ sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常；
> ④ sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性。

## 请你说明一下在监视器(Monitor)内部，是如何做到线程同步的？在程序又应该做哪种级别的同步呢？ 

考察点：JAVA线程同步

**参考回答：**

> 监视器和锁在Java虚拟机中是一块使用的。监视器监视一块同步代码块，确保一次只有一个线程执行同步代码块。每一个监视器都和一个对象引用相关联。线程在获取锁之前不允许执行同步代码。

## 请分析一下同步方法和同步代码块的区别是什么？

考察点：JAVA代码块同步

**参考回答：**

> 区别：
> 同步方法默认用this或者当前类class对象作为锁；
> 同步代码块可以选择以什么来加锁，比同步方法要更细颗粒度，我们可以选择只同步会发生同步问题的部分代码而不是整个方法。

## 通过Callable和Future创建线程

> （1）创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且有返回值。
>
> （2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该			Callable对象的call()方法的返回值。
>
> （3）使用FutureTask对象作为Thread对象的target创建并启动新线程。
>
> （4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值



代码：

```
package com.thread;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.FutureTask;
  
public class CallableThreadTest implements Callable<Integer>
{
  
    public static void main(String[] args)
    {
        CallableThreadTest ctt = new CallableThreadTest();
        FutureTask<Integer> ft = new FutureTask<>(ctt);
        for(int i = 0;i < 100;i++)
        {
            System.out.println(Thread.currentThread().getName()+" 的循环变量i的值"+i);
            if(i==20)
            {
                new Thread(ft,"有返回值的线程").start();
            }
        }
        try
        {
            System.out.println("子线程的返回值："+ft.get());
        } catch (InterruptedException e)
        {
            e.printStackTrace();
        } catch (ExecutionException e)
        {
            e.printStackTrace();
        }
  
    }
  
    @Override
    public Integer call() throws Exception
    {
        int i = 0;
        for(;i<100;i++)
        {
            System.out.println(Thread.currentThread().getName()+" "+i);
        }
        return i;
    }
  
}
```



## 请简要说明一下JAVA中cyclicbarrier和countdownlatch的区别分别是什么？

考察点：线程

**参考回答：**

> CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同：
>
> CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；
>
> 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；
>
> 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。



## 请你解释一下什么是线程池（thread pool）？

考察点：线程池

**参考回答：**

> ​	在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在Java中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。
>
> ​	Java 5+中的Executor接口定义一个执行线程的工具。它的子类型即线程池接口是ExecutorService。要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，因此在工具类Executors面提供了一些静态工厂方法，生成一些常用的线程池，如下所示：
> \- newSingleThreadExecutor：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。
> \- newFixedThreadPool：创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。
> \- newCachedThreadPool：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。
> \- newScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。

##  请说明一下线程池有什么优势？

考察点：线程池

**参考回答：**

> 第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
>
> 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能执行。
>
> 第三：提高线程的可管理性，线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。

## 请简短说明一下你对AQS的理解。

考察点：多线程

**参考回答：**

> AQS其实就是一个可以给我们实现锁的框架
> 内部实现的关键是：先进先出的队列、state状态
> 定义了内部类ConditionObject
> 拥有两种线程模式独占模式和共享模式。
> 在LOCK包中的相关锁(常用的有ReentrantLock、 ReadWriteLock)都是基于AQS来构建，一般我们叫AQS为同步器。

## 请简述一下线程池的运行流程，使用参数以及方法策略等

考察点：线程池

**参考回答：**

> 线程池主要就是指定线程池核心线程数大小，最大线程数，存储的队列，拒绝策略，空闲线程存活时长。当需要任务大于核心线程数时候，就开始把任务往存储任务的队列里，当存储队列满了的话，就开始增加线程池创建的线程数量，如果当线程数量也达到了最大，就开始执行拒绝策略，比如说记录日志，直接丢弃，或者丢弃最老的任务。

## 线程核心参数？ 如何合理配置线程池参数？

**corePoolSize**（核心线程数）

> （1）核心线程会一直存在，即使没有任务执行； 
>
> （2）当线程数小于核心线程数的时候，即使有空闲线程，也会一直创建线程直到达到核心线程数；
> （3）设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭。

**queueCapacity**（任务队列容量）

> 也叫阻塞队列，当核心线程都在运行，此时再有任务进来，会进入任务队列，排队等待线程执行。

**maxPoolSize**（最大线程数）

> (1）线程池里允许存在的最大线程数量；
> (2）当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务；
> (3）线程池里允许存在的最大线程数量。当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务。

**keepAliveTime**（线程空闲时间）

> (1）当线程空闲时间达到keepAliveTime时，线程会退出（关闭），直到线程数等于核心线程数；
> (2）如果设置了allowCoreThreadTimeout=true，则线程会退出直到线程数等于零。

**allowCoreThreadTimeout**（允许核心线程超时）

**rejectedExecutionHandler**（任务拒绝处理器）

> (1）当线程数量达到最大线程数，且任务队列已满时，会拒绝任务；
> (2）调用线程池shutdown()方法后，会等待执行完线程池的任务之后，再shutdown()。如果在调用了shutdown()方法和线程池真正shutdown()之间提交任务，会拒绝新任务。

推荐配置

```
corePoolSize = 1
queueCapacity = Integer.MAX_VALUE
maxPoolSize = Integer.MAX_VALUE
keepAliveTime = 60秒
allowCoreThreadTimeout = false
rejectedExecutionHandler = AbortPolicy()
```



## 请介绍一下什么是生产者消费者模式？

考察点：线程

**参考回答：**

![img](https://uploadfiles.nowcoder.com/images/20180925/308572_1537880635592_7142B8354CA8A352B2B805F997C71549)

> 生产者消费者问题是线程模型中的经典问题：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者取走数据。

优点：支持并发、解耦。

## ThreadLocal

> 首先ThreadLocal 是一个线程的局部变量(其实就是一个Map),ThreadLocal会为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，将对象的可见范围限制在同一个线程内，而不会影响其它线程所对应的副本。
> 这样做其实就是以空间换时间的方式(与synchronized相反)，以耗费内存为代价，单大大减少了线程同步(如synchronized)所带来性能消耗以及减少了线程并发控制的复杂度。

**ThreadLoca类中提供了几个常用方法**

```
	public T get() { }---获取ThreadLocal在当前线程中保存的变量副本
    public void set(T value) { }---设置当前线程中变量的副本
    public void remove() { }---移除当前线程中变量的副本
    protected T initialValue() { }---protected修饰的方法。
    ThreadLocal提供的只是一个浅拷贝，如果变量是一个引用类型，那么就要重写该函数来实现深拷贝。建议在使用ThreadLocal一开始时就重写该函数

```

> ThreadLocal的设计初衷就是为了避免多个线程去并发访问同一个对象，尽管它是线程安全的。因此如果用普遍的方法，通过一个全局的线程安全的map来存储多个线程的变量副本就违背了ThreadLocal的本意。在每个Thread中存放与它关联的ThreadLocalMap是完全符合其设计思想的。当想对线程局部变量进行操作时，只要把Thread作为key来获取Thread中的ThreadLocalMap即可。这种设计相比采用一个全局map的方法会占用很多内存空间，但其不需要额外采取锁等线程同步方法而节省了时间上的消耗。

> Synchronized却正好相反，它用于在多个线程间通信时能够获得数据共享。即Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。所以ThreadLocal并不能代替synchronized，Synchronized的功能范围更广(同步机制)。

## **ThreadLocal中的内存泄露问题：**

> 如果ThreadLocal被设置为null后，并且没有任何强引用指向它，根据垃圾回收的可达性分析算法，ThreadLocal将被回收。这样的话，ThreadLocalMap中就会含有key为null的Entry，而且ThreadLocalMap是在Thread中的，只要线程迟迟不结束，这些无法访问到的value就会形成内存泄露。为了解决这个问题，ThreadLocalMap中的getEntry()、set()和remove()函数都会清理key为null的Entry，以下面的getEntry()函数为例。
> 

```
private Entry getEntry(ThreadLocal<?> key) {
            int i = key.threadLocalHashCode & (table.length - 1);
            Entry e = table[i];
            if (e != null && e.get() == key)
                return e;
            else
                return getEntryAfterMiss(key, i, e);
}
private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {
            Entry[] tab = table;
            int len = tab.length;

            while (e != null) {
                ThreadLocal<?> k = e.get();
                if (k == key)
                    return e;
                if (k == null)
                    expungeStaleEntry(i);
                else
                    i = nextIndex(i, len);
                e = tab[i];
            }
}
```

要注意的是ThreadLocalMap的key是一个弱引用。在这里我们分析一下强引用key和弱引用key的差别

> 强引用key：ThreadLocal被设置为null，由于ThreadLocalMap持有ThreadLocal的强引用，如果不手动删除，那么ThreadLocal将不会回收，产生内存泄漏。

> 弱引用key：ThreadLocal被设置为null，由于ThreadLocalMap持有ThreadLocal的弱引用，即便不手动删除，ThreadLocal仍会被回收，ThreadLocalMap在之后调用set()、getEntry()和remove()函数时会清除所有key为null的Entry。

> ThreadLocalMap仅仅含有这些被动措施来补救内存泄露问题，如果在之后没有调用ThreadLocalMap的set()、getEntry()和remove()函数的话，那么仍然会存在内存泄漏问题。在使用线程池的情况下，如果不及时进行清理，内存泄漏问题事小，甚至还会产生程序逻辑上的问题。所以，为了安全地使用ThreadLocal，必须要像每次使用完锁就解锁一样，在每次使用完ThreadLocal后都要调用remove()来清理无用的Entry。
> 